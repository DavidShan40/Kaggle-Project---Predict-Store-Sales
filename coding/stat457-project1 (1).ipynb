{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import library\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nimport string\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import GridSearchCV, cross_val_predict, StratifiedShuffleSplit\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read raw dataset\n\nstore_info = pd.read_csv('../input/w21proj1/W21_store_info.csv')\ntest = pd.read_csv('../input/w21proj1/W21_test.csv')\ntrain = pd.read_csv('../input/w21proj1/W21_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()\n#train.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since ID is not in training data, customers is not in testing data, delete them.\nBut by prof's advice, we may predict customer first, then predict the price. Just keep it now."},{"metadata":{"trusted":true},"cell_type":"code","source":"del test['ID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_info.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I found that store indo can be included in training and testing set, since there is a common column store."},{"metadata":{"trusted":true},"cell_type":"code","source":"store_info['PromoInterval'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"since PromoInterval is same for all kinds of stores, delete it."},{"metadata":{"trusted":true},"cell_type":"code","source":"del store_info['PromoInterval']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create new features with date object "},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Date'] = pd.to_datetime(train['Date'])   \ntrain['year'] = train.Date.dt.year\ntrain['month'] = train.Date.dt.month\ntrain['day'] = train.Date.dt.day\ntrain.drop('Date', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Date'] = pd.to_datetime(test['Date'])   \ntest['year'] = test.Date.dt.year\ntest['month'] = test.Date.dt.month\ntest['day'] = test.Date.dt.day\ntest.drop('Date', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge dataset without change sequence.\n\n\n#for store in store_info[,0]:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine store_info and training & testing data\ntrain_merge = train.merge(train.merge(store_info, how='left', on='Store', sort=False))\ntest_merge = test.merge(test.merge(store_info, how='left', on='Store', sort=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_merge.shape\n# train_merge.columns\ntest_merge.head(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_merge.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 13 columns in training dataset. Date and StoreType are cateogrical type, the others are numeric type."},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample data has lower datapoints for visualization\n\nsample_data = train_merge.sample(frac = 0.1, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"fig = plt.figure(figsize=(12,16))\nfor index,col in enumerate(sample_data.columns):\n    plt.subplot(4,4,index+1)\n    sns.countplot(sample_data[sample_data.columns].loc[:,col].dropna())\nfig.tight_layout(pad=1.0)"},{"metadata":{},"cell_type":"markdown","source":"Sales, customers and Competition distance are numerical continuous data.\nDate of week, open, promo, School holiday are numerical discrete data.\nThe others are categorical\nAlso, States holiday is sparse data, with most count as 0. Delete it."},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_merge['StateHoliday']\ndel test_merge['StateHoliday']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We found that most of them are 0. (about 97%)"},{"metadata":{},"cell_type":"markdown","source":"To reduce multicollinearity, delete one of the pairs of columns that has correlation above 0.95"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_merge.Sales.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train_merge.corr(), annot = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"find pairs of correlation above 0.95 & below 0.01"},{"metadata":{"trusted":true},"cell_type":"code","source":"def corrFilter(x: pd.DataFrame, bound: float):\n    xCorr = x.corr()\n    xFiltered = xCorr[((xCorr >= bound) | (xCorr <= -bound)) & (xCorr !=1.000)]\n    xFlattened = xFiltered.unstack().sort_values().drop_duplicates()\n    return xFlattened\n\ncorrFilter(train_merge, .95)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def corrFilterLow(x: pd.DataFrame, bound: float):\n    xCorr = abs(x.corr())\n    xFiltered = xCorr[(xCorr <= bound) | (xCorr <= -bound) & (xCorr !=1.000)]\n    xFlattened = xFiltered.unstack().sort_values().drop_duplicates()\n    return xFlattened\n\ncorrFilterLow(train_merge, .01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrFilterLow(train_merge, .01).index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no columns need be delete, but sales and customer has a high correlation.\n\nAlso, from the heat map, open and promo has high correlation with sales. Let's find the relationship. Since open and promo are values of 0 and 1, check if open/protmo is 0, sales is 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"# scatter plot \ntrain_merge.value_counts(subset=['Open', 'Sales'])\n# Hence, when open is 0, sales = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_merge.value_counts(subset=['Open', 'Sales'])[1].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It shows when open is 0, sales is 0. The other values are evenly distributed."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_merge.value_counts(subset=['Promo', 'Sales'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_merge.value_counts(subset=['Open'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_merge.value_counts(subset=['Sales'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_merge.value_counts(subset=['Promo'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"there is about 25% of Sales is 0, when protmo is 0."},{"metadata":{},"cell_type":"markdown","source":"Total number of open = 0 is 3103. when open is 0, sales is 0 for 3103 rows. The total number of 0s in sales is 3105, which is close to 3103. So now, I consider when the open is 0, predit sales is 0. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train_merge[train_merge[\"Open\"] != 0].drop('Open', axis =1).corr(), annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_merge.Sales.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clustering","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nle = LabelEncoder()\ntrain_merge['StoreType'] = le.fit_transform(train_merge['StoreType'])\ntest_merge['StoreType'] = le.fit_transform(test_merge['StoreType'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_merge.head()\ntest_merge.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_merge.head(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save current data, for doing prediction in R\ntest_merge.to_csv(\"../../kaggle/working/test_engineered.csv\", index=False)\ntrain_merge.to_csv(\"../../kaggle/working/train_engineered.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Prediction models"},{"metadata":{},"cell_type":"markdown","source":"2.1 simple prediction\n\nI want to try several models: KNN regression, Logistic regression, Random Forest Regression, MLP neural network, CNN model. I'm using cross_validation to evaluate each model's performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"# root mean squared percentage error\n\ndef rmspe(y_true, y_pred):\n    return (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = train_merge.drop(['Sales'], axis = 1)\ntrain_y = train_merge['Sales']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change storetype to numeric\n\nle = LabelEncoder()\ntrain_X['StoreType'] = le.fit_transform(train_X['StoreType'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KNeighborsRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import StratifiedKFold\n\nN = 5  # number of folds\nskf = StratifiedKFold(n_splits=N, random_state=5, shuffle=True)\nnum = 0\nsales = pd.DataFrame(np.zeros((len(train_X), N)), columns=['Fold_{}'.format(i) for i in range(1, N + 1)])\nRMSPE_score_lis = []\n\nfor train_index, test_index in skf.split(train_X, train_y):\n    num +=1\n    X_train1, X_test1 = train_X.iloc[train_index,:], train_X.iloc[test_index,:]\n    y_train1, y_test1 = train_y[train_index], train_y[test_index]\n    \n    model = model\n    model.fit(X_train1, y_train1)\n    \n    #saleprice.loc[:, 'Fold_{}'.format(num)] = model.predict(test_data)\n    prediction = model.predict(X_test1)\n    #RMSPE score\n    RMSPE_score = rmspe(y_test1, prediction)\n    RMSPE_score_lis = RMSPE_score_lis + [RMSPE_score]\n    #print(\"RMSPE score: \", RMSPE_score)\nprint(\"average RMSPE score:\",sum(RMSPE_score_lis)/5) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Stratified_model(model, train_X, train_y, N = 5, random_state=5):\n\n    skf = StratifiedKFold(n_splits=N, random_state=random_state, shuffle=True)\n    num = 0\n    sales = pd.DataFrame(np.zeros((len(train_X), N)), columns=['Fold_{}'.format(i) for i in range(1, N + 1)])\n    RMSPE_score_lis = []\n\n    for train_index, test_index in skf.split(train_X, train_y):\n        num +=1\n        X_train1, X_test1 = train_X.iloc[train_index,:], train_X.iloc[test_index,:]\n        y_train1, y_test1 = train_y[train_index], train_y[test_index]\n\n        model = model\n        model.fit(X_train1, y_train1)\n\n        #saleprice.loc[:, 'Fold_{}'.format(num)] = model.predict(test_data)\n        prediction = model.predict(X_test1)\n        #RMSPE score\n        RMSPE_score = rmspe(y_test1, prediction)\n        RMSPE_score_lis = RMSPE_score_lis + [RMSPE_score]\n        #print(\"RMSPE score: \", RMSPE_score)\n    print(\"average RMSPE score:\",sum(RMSPE_score_lis)/5) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check if cross-validation works\n\nStratified_model(model, train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression\n\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(random_state=0)\nStratified_model(model, train_X, train_y)"},{"metadata":{},"cell_type":"markdown","source":"# Random Forest\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodel = RandomForestRegressor(random_state=0)\nStratified_model(model, train_X, train_y)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# MLP neural network\n\nStratified_model(model, train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CNN","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"normal method without cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(train_X, train_y,\n                                                    test_size=0.2,\n                                                    random_state=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_func(model, x_train = x_train, y_train = y_train, x_test = x_test, y_test = y_test, random_state=5):\n    model.fit(x_train, y_train)\n    prediction = model.predict(x_test)\n    RMSPE_score = rmspe(y_test, prediction)\n    print(\"RMSPE score: \", RMSPE_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KNeighborsRegressor()\nmodel_func(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(random_state=0)\nmodel_func(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestRegressor(random_state=0)\nmodel_func(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MLP"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\n\nmodel = MLPRegressor(random_state=0, max_iter = 200)\nmodel_func(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}